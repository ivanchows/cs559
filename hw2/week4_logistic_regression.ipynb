{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "0ZD6N9vTMv4a"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = pd.DataFrame(data.target, columns=['TARGET'])\n",
        "\n",
        "#X.head(), y.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split into Training and Test"
      ],
      "metadata": {
        "id": "C6rjZqSxNpzg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "positive_ratio = np.mean(y.values.ravel()) * 100\n",
        "negative_ratio = 100 - positive_ratio\n",
        "print(f\"Positive Ratio: {positive_ratio:.2f}\")\n",
        "print(f\"Positive Ratio: {positive_ratio:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2TOzKgQNkBj",
        "outputId": "5b0a6262-7ad1-4ff9-95ac-d1b08e05004f"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive Ratio: 62.74\n",
            "Positive Ratio: 62.74\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "k2gMmaooNpRz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 80% training 20% testing\n",
        "\n",
        "def manual_train_test_split(X, y, test_size=0.2):\n",
        "    # Get the number of data points\n",
        "    num_data_points = X.shape[0]\n",
        "\n",
        "    # Generate shuffled indices\n",
        "    shuffled_indices = np.random.permutation(num_data_points)\n",
        "\n",
        "    # Calculate the number of test samples\n",
        "    test_set_size = int(num_data_points * test_size)\n",
        "\n",
        "    # Split indices into test and train\n",
        "    test_indices = shuffled_indices[:test_set_size]\n",
        "    train_indices = shuffled_indices[test_set_size:]\n",
        "\n",
        "    # Use the indices to split the data\n",
        "    X_train = X.iloc[train_indices]\n",
        "    X_test = X.iloc[test_indices]\n",
        "    y_train = y.iloc[train_indices]\n",
        "    y_test = y.iloc[test_indices]\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "# Perform the manual train-test split\n",
        "X_train, X_test, y_train, y_test = manual_train_test_split(X, y, test_size=0.2)"
      ],
      "metadata": {
        "id": "dbDcf_LsNgT0"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZK2YCQlOcc1",
        "outputId": "7ee9e36d-dcb8-4712-a6a9-8a7f7187b8a1"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((456, 30), (113, 30))"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_intercept = np.column_stack([np.ones(X_train.shape[0]), X_train])\n",
        "X_test_intercept = np.column_stack([np.ones(X_test.shape[0]), X_test])"
      ],
      "metadata": {
        "id": "P7t9T_E1Ohp8"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sigmoid Function\n"
      ],
      "metadata": {
        "id": "XWt3B33OPCdc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "  return 1 / (1 + np.exp(-z))\n",
        "\n",
        "# cost function (log - loss)\n",
        "def compute_cost(X, y, theta):\n",
        "  m = len(y)\n",
        "  h = sigmoid(np.dot(X, theta))\n",
        "  epsilon = 1e-5\n",
        "  cost = -(1/m) * np.sum(y * np.log(h + epsilon) + (1-y) * np.log(1 - h + epsilon))\n",
        "  return cost"
      ],
      "metadata": {
        "id": "-bdSLyIfOoTi"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradient Descent"
      ],
      "metadata": {
        "id": "4LQxgkE8Qsry"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(X, y, theta, alpha, iterations):\n",
        "  m = len(y)\n",
        "  cost_history = []\n",
        "\n",
        "  for i in range(iterations):\n",
        "    h = sigmoid(np.dot(X, theta))\n",
        "    gradient = np.dot(X.T, (h-y)) / m\n",
        "    theta = theta - alpha * gradient\n",
        "    cost = compute_cost(X, y, theta)\n",
        "    cost_history.append(cost)\n",
        "    if i % 100 == 0:\n",
        "      print(f\"iterations: {i}, loss:{cost}\")\n",
        "  return theta, cost_history"
      ],
      "metadata": {
        "id": "PbUjOZMcPdon"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize parameters\n",
        "theta = np.zeros(X_train_intercept.shape[1])\n",
        "\n",
        "# convert y_train and y_test to 1D numpy arrays\n",
        "y_train = y_train.values.ravel() # flatten dataframe to 1d array\n",
        "y_test = y_test.values.ravel()  # flatten dataframe to 1d array"
      ],
      "metadata": {
        "id": "soSAzWqdQl3k"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train model\n",
        "alpha = 0.00001\n",
        "iterations = 1000\n",
        "theta, cost_history = gradient_descent(X_train_intercept, y_train, theta, alpha, iterations)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hoo6lbjBQ_le",
        "outputId": "2f753e94-db14-428a-99b8-2082b0bfd836"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iterations: 0, loss:0.7632479662291021\n",
            "iterations: 100, loss:0.4966270349432795\n",
            "iterations: 200, loss:0.35293776113654957\n",
            "iterations: 300, loss:0.32055304092153064\n",
            "iterations: 400, loss:0.2980142090140103\n",
            "iterations: 500, loss:0.2816363509090987\n",
            "iterations: 600, loss:0.26926637427271366\n",
            "iterations: 700, loss:0.2595775390775874\n",
            "iterations: 800, loss:0.25175425981300875\n",
            "iterations: 900, loss:0.2452812651925\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_prob = sigmoid(np.dot(X_test_intercept, theta))\n",
        "y_pred_test = (y_pred_prob >= 0.5).astype(int)"
      ],
      "metadata": {
        "id": "_hg3JvMeRb5U"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = np.mean(y_pred_test == y_test) * 100\n",
        "print(f\"Accuracy on test set (manual logistic regression): {accuracy}%\")\n",
        "\n",
        "precision_manual = precision_score(y_test, y_pred_test)\n",
        "recall_manual = recall_score(y_test, y_pred_test)\n",
        "f1_manual = f1_score(y_test, y_pred_test)\n",
        "\n",
        "print(f\"Precision (manual logistic regression): {precision_manual}\")\n",
        "print(f\"Recall (manual logistic regression): {recall_manual}\")\n",
        "print(f\"F1 Score (manual logistic regression): {f1_manual}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nORg3FbkRkAN",
        "outputId": "2eb2f81c-6955-4f6a-cf94-263291575ab9"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on test set (manual logistic regression): 88.49557522123894%\n",
            "Precision (manual logistic regression): 0.8831168831168831\n",
            "Recall (manual logistic regression): 0.9444444444444444\n",
            "F1 Score (manual logistic regression): 0.912751677852349\n"
          ]
        }
      ]
    }
  ]
}